{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pyspark.sql.functions import concat, to_timestamp, col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/12/27 20:33:47 WARN Utils: Your hostname, J4Hp resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/12/27 20:33:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/27 20:33:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/27 20:33:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as spark_sum, col, hour, concat_ws, to_date, date_format\n",
    "# Stop any existing Spark session\n",
    "# Step 1: Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataProcessing\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "# Step 2: Load your CSV file into a Spark DataFrame\n",
    "data = spark.read.csv(\"June2024.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Define the specific time range\n",
    "start_time = \"12:45:00\"\n",
    "end_time = \"14:45:00\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp, concat, col, lit, date_format, expr\n",
    "# Filter rows where ROUTE_ID is 'acwXkRFM'\n",
    "# data = data.filter(col(\"ROUTE_ID\") == 'acwXkRFM')\n",
    "# Step 2: Format TICKET_ISSUE_TIME as a string in \"HH:mm:ss\" format (if not already) and combine date and time\n",
    "\n",
    "data = data.withColumn(\"TICKET_ISSUE_TIME_STR\", date_format(col(\"TICKET_ISSUE_TIME\"), \"HH:mm:ss\"))\n",
    "# Filter rows within the specific time range\n",
    "# Show data which has time other than start_time and end_time\n",
    "\n",
    "data = data.filter((col(\"TICKET_ISSUE_TIME_STR\") >= start_time) & (col(\"TICKET_ISSUE_TIME_STR\") <= end_time))\n",
    "# Calculate the total number of days in the dataset\n",
    "total_days = data.select(to_date(col(\"TICKET_ISSUE_DATE\")).alias(\"date\")).distinct().count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import folium\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "LIMIT_OF_TOP_BUS_STOPS = 600\n",
    "MIN_AVG_THRESHOLD = 5\n",
    "# Aggregate data to get total passenger count per bus stop within the time range\n",
    "# Sort by total passengers in descending order and select the top 20\n",
    "top_bus_stops = (\n",
    "    data.groupBy(\"FROM_STOP_NAME\")\n",
    "    .agg(F.sum(\"TOTAL_PASSENGER\").alias(\"TOTAL_PASSENGER\"))\n",
    "    .withColumn(\"AVERAGE_PASSENGER\", F.col(\"TOTAL_PASSENGER\") / total_days)\n",
    "    .filter(F.col(\"AVERAGE_PASSENGER\") >= MIN_AVG_THRESHOLD)\n",
    "    .orderBy(\"TOTAL_PASSENGER\", ascending=False)\n",
    "    .limit(LIMIT_OF_TOP_BUS_STOPS)\n",
    "    .collect()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================= ] 100.0%\n",
      "Geocoding Successes: 339\n",
      "Geocoding Failures: 196\n",
      "Failed to geocode the following bus stops:\n",
      "['Statue Sbi (outside South India)', 'World Market (outside South India)', 'Chakai (outside South India)', 'Easwara Vilasam Cotton Hill School', 'Rotary (outside South India)', 'Kazhakkoottam Railway Station', 'East Fort South Stand 2', 'Mangalapuram East', '16th Mile (outside South India)', 'Aiyroopara', 'Pettah Pallimukku Junction', 'Thrikkannapuram (outside South India)', 'Mamam (outside South India)', 'Kachani Junction', 'Kalliyoor Grama Panchayath Office', 'Puthanpalam', 'Kalliyodu', 'Melathumele', 'Kayalkara', 'Kudappanakunnu Bank Junction', 'Civil Station Junction Kudappanakunnu', 'Panangodu Junction', 'Thekkada Junction', 'Pullampara Palam', 'Oorambu', 'Titanium (outside South India)', 'East Mukkola', 'Mananthala (outside South India)', 'Veli Church (outside South India)', 'Paruthikkuzhy', 'Sainik School (outside South India)', 'Saraswathy Vidyalaya School (outside South India)', 'Punchakkari', 'Vellarada Ksrtc Depot', 'Vavara Ambalam', 'Military Hospital Pangodu', 'Irinchayam Steps', 'Vazhavilapaalam', 'Karamana Sivan Kovil', 'Perunelli', 'Beemapalli Back', 'Pazhayakada Junction', 'Venkavila Junction', 'Kottarakkari', 'Karipur (outside South India)', 'Maithani (outside South India)', 'Water Tank Pallithura', 'Irumpa', 'Killy (outside South India)', 'Cheru Vettukadu', '6th Stone Vazhayila', 'Malamelkunnu', 'Kattadimukku', 'Azhikode (outside South India)', 'Edapazhanji Pangode Fish Market', 'Museum (outside South India)', 'Statue (outside South India)', 'Ookkodu', 'Arumanior Junction', 'Puthiyathura Junction', 'Chempoor Junction', 'Mithrumala', 'Channakara', 'Vamanapuram Phc', 'Pulinkudy', 'Ks Road Kovalam Junction', 'Chenkavila Junction', 'Olathanni Junction', 'Puthuveettumele', 'Kodungavila', 'St Andrews (outside South India)', 'Postoffice Junction Parassala', 'Narmadha Toll Junction', 'Muthalapozhi Palam', 'Pezhummoodu Junction', 'Valliya Kattayikkal', 'Panagod', 'Karikkakom Vayanasala', 'Bakery Junction (outside South India)', 'Block Junction Venkavila', 'Vijayamohinim Mill', 'Konkalam Junction', 'Nannattukavu A', 'Post Office Manivila', 'Edavacode', 'Vandannur', 'Kanjirampara Junction', 'Mele Aramthanam', 'Madhupalam', 'Thumpod', 'Poovar Junction', 'Muttada St Joseph School', 'Poomalliyoorkonam', 'Mangodu Temple', '10th Stone Patham Kallu', '28th Mile (outside South India)', 'Plamood Pothencode', 'Kuzhivettanvila', 'Chekkalamukku', 'Chadayamangalam Bus Stand', 'Aramada (outside South India)', 'Eettimmodu', 'Powdikonam Melemukku', 'Thekkada Stpes', 'Pachaloor Chudukadu Temple', 'Puliyankode', 'Poovanathin Moodu', 'Scooter Factory (outside South India)', 'Lords (outside South India)', 'Pump House (outside South India)', \"St Joseph's School Muttada\", 'Chalakuzhy', 'Chittalloor Temple', 'Villant (outside South India)', 'Puthukurichi Post Office', 'Aramada Good Shepherd', 'J T S Mancha (outside South India)', 'Bhagat Singh Road (outside South India)', 'Aruvattukonam Point', 'Chengalloor Hll', 'Kanakkod (outside South India)', 'Urban P H C Muttada', 'Doordarshan (outside South India)', 'Concordia Lutheran High School (outside South India)', 'Fci (outside South India)', 'Kudappanakunnu Civil Station Jn']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Latitude and Longitude bounds for South India\n",
    "SOUTH_INDIA_LAT_MIN = 8.0\n",
    "SOUTH_INDIA_LAT_MAX = 14.5\n",
    "SOUTH_INDIA_LON_MIN = 76.0\n",
    "SOUTH_INDIA_LON_MAX = 85.0\n",
    "\n",
    "# File to store previously geocoded bus stops\n",
    "GEO_CACHE_FILE = 'geocoded_stops.json'\n",
    "FAILURE_CACHE_FILE = 'geocoding_failures.json'\n",
    "\n",
    "# Function to load previously cached geocoded data from a JSON file\n",
    "def load_geocoded_data():\n",
    "    try:\n",
    "        with open(GEO_CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Function to save geocoded data to a JSON file\n",
    "def save_geocoded_data(data):\n",
    "    with open(GEO_CACHE_FILE, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Function to check if a location is in South India\n",
    "def is_in_south_india(latitude, longitude):\n",
    "    return (SOUTH_INDIA_LAT_MIN <= latitude <= SOUTH_INDIA_LAT_MAX) and (SOUTH_INDIA_LON_MIN <= longitude <= SOUTH_INDIA_LON_MAX)\n",
    "\n",
    "def load_geocoded_failures():\n",
    "    try:\n",
    "        with open(FAILURE_CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Prepare data for geocoding (replace 'top_bus_stops' with your actual data)\n",
    "bus_stops_data = [{\"stop_name\": row[\"FROM_STOP_NAME\"], \"passenger_count\": row[\"AVERAGE_PASSENGER\"]} for row in top_bus_stops]\n",
    "\n",
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"bus_stop_locator\")\n",
    "\n",
    "# Load previously geocoded data from the cache\n",
    "cached_data = load_geocoded_data()\n",
    "cached_failure_data = load_geocoded_failures()\n",
    "\n",
    "# Initialize counters for success and failure\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "failures = []\n",
    "\n",
    "# Function to print the progress bar\n",
    "def print_progress_bar(iteration, total, bar_length=40):\n",
    "    progress = iteration / total\n",
    "    arrow = '=' * int(round(progress * bar_length) - 1)\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    percent = round(progress * 100, 1)\n",
    "    sys.stdout.write(f'\\r[{arrow}{spaces}] {percent}%')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Geocode each bus stop with exponential backoff\n",
    "for i, stop in enumerate(bus_stops_data):\n",
    "    stop_name = stop[\"stop_name\"]\n",
    "    \n",
    "    # Skip if the stop is in the failures list\n",
    "    if stop_name in cached_data:\n",
    "        # Use cached data\n",
    "        stop[\"latitude\"] = cached_data[stop_name][\"latitude\"]\n",
    "        stop[\"longitude\"] = cached_data[stop_name][\"longitude\"]\n",
    "        success_count += 1  # Increment success count for cached data\n",
    "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
    "        continue  # Skip geocoding since it's already cached\n",
    "    elif stop_name in cached_failure_data:\n",
    "        # Skip geocoding if it previously failed\n",
    "        failure_count += 1\n",
    "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
    "        continue\n",
    "\n",
    "    # If not cached, geocode this stop\n",
    "    retries = 0  # Counter for retry attempts\n",
    "    while retries < 5:\n",
    "        try:\n",
    "            # Geocode the stop with a timeout\n",
    "            location = geolocator.geocode(stop_name, timeout=20)\n",
    "\n",
    "            if location:\n",
    "                latitude = location.latitude\n",
    "                longitude = location.longitude\n",
    "\n",
    "                # Check if the coordinates are within South India's bounds\n",
    "                if is_in_south_india(latitude, longitude):\n",
    "                    stop[\"latitude\"] = latitude\n",
    "                    stop[\"longitude\"] = longitude\n",
    "                    # Save the geocoded result in the cache\n",
    "                    cached_data[stop_name] = {\"latitude\": stop[\"latitude\"], \"longitude\": stop[\"longitude\"]}\n",
    "                    success_count += 1  # Increment success count\n",
    "                else:\n",
    "                    # If outside South India, mark as None\n",
    "                    stop[\"latitude\"] = None\n",
    "                    stop[\"longitude\"] = None\n",
    "                    failure_count += 1  # Increment failure count\n",
    "                    failures.append(f\"{stop_name} (outside South India)\")\n",
    "            else:\n",
    "                stop[\"latitude\"] = None\n",
    "                stop[\"longitude\"] = None\n",
    "                failure_count += 1  # Increment failure count\n",
    "                failures.append(stop_name)\n",
    "\n",
    "            break  # Exit the retry loop on success\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Error geocoding {stop_name}: {e}\")\n",
    "            stop[\"latitude\"] = None\n",
    "            stop[\"longitude\"] = None\n",
    "            failures.append(stop_name)\n",
    "            failure_count += 1  # Increment failure count\n",
    "\n",
    "            # Exponential backoff\n",
    "            backoff_time = min(2 ** retries + random.uniform(0, 1), 30)  # max backoff of 30 seconds\n",
    "            print(f\"Retrying {stop_name} in {backoff_time:.2f} seconds...\")\n",
    "            time.sleep(backoff_time)  # Sleep exponentially between retries\n",
    "\n",
    "    # If retries are exhausted, skip to the next stop\n",
    "    if retries == 3:\n",
    "        print(f\"Failed to geocode {stop_name} after {retries} retries.\")\n",
    "    \n",
    "    # Update progress bar\n",
    "    print_progress_bar(i + 1, len(bus_stops_data))\n",
    "\n",
    "# Save the updated geocoded data to the cache file\n",
    "save_geocoded_data(cached_data)\n",
    "\n",
    "# Output the number of successes and failures\n",
    "print(f\"\\nGeocoding Successes: {success_count}\")\n",
    "print(f\"Geocoding Failures: {failure_count}\")\n",
    "if failures:\n",
    "    print(\"Failed to geocode the following bus stops:\")\n",
    "    print(failures)\n",
    "\n",
    "    # Function to save geocoding failures to a JSON file\n",
    "    def save_geocoding_failures(failures):\n",
    "        with open(FAILURE_CACHE_FILE, 'w') as f:\n",
    "            json.dump(failures, f, indent=4)\n",
    "\n",
    "    # Save the geocoding failures to the cache file\n",
    "    save_geocoding_failures(failures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bus_stops_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Filter out stops without coordinates\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m stops_with_coords \u001b[38;5;241m=\u001b[39m [stop \u001b[38;5;28;01mfor\u001b[39;00m stop \u001b[38;5;129;01min\u001b[39;00m \u001b[43mbus_stops_data\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stop \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stop \u001b[38;5;129;01mand\u001b[39;00m stop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m stop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to Pandas DataFrame for easier handling with Folium\u001b[39;00m\n\u001b[1;32m     12\u001b[0m stops_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stops_with_coords)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bus_stops_data' is not defined"
     ]
    }
   ],
   "source": [
    "from folium.plugins import HeatMap\n",
    "import folium\n",
    "import pandas as pd\n",
    "from folium import Icon\n",
    "from folium.plugins import MarkerCluster\n",
    "import numpy as np\n",
    "\n",
    "# Filter out stops without coordinates\n",
    "stops_with_coords = [stop for stop in bus_stops_data if 'latitude' in stop and 'longitude' in stop and stop[\"latitude\"] is not None and stop[\"longitude\"] is not None]\n",
    "\n",
    "# Convert to Pandas DataFrame for easier handling with Folium\n",
    "stops_df = pd.DataFrame(stops_with_coords)\n",
    "\n",
    "# Initialize a Folium map centered around an average location\n",
    "map_center = [8.4869, 76.9529]\n",
    "m = folium.Map(location=map_center, tiles=\"CartoDB positron\", zoom_start=13, min_zoom=8, max_zoom=18)\n",
    "\n",
    "# Logarithmic transformation of passenger counts for better contrast in markers\n",
    "stops_df['log_passenger_count'] = np.log1p(stops_df['passenger_count'])\n",
    "\n",
    "# Prepare data for HeatMap using actual passenger counts for intensity\n",
    "heat_data = []\n",
    "for _, row in stops_df.iterrows():\n",
    "    heat_data.append([row[\"latitude\"], row[\"longitude\"], row[\"passenger_count\"]])  # Using actual count for heatmap\n",
    "\n",
    "# Create the HeatMap layer with adjusted visual settings\n",
    "HeatMap(\n",
    "    heat_data,\n",
    "    min_opacity=0.3,  # Set minimum opacity for better visibility (not too faint)\n",
    "    max_opacity=0.7,  # Set maximum opacity for a more subtle heatmap\n",
    "    radius=25,        # Adjust radius size to balance between clarity and overlap\n",
    "    blur=18,          # Moderate blur to avoid excessive smoothing\n",
    "    gradient={        # Reduced 5-color gradient scale for better distinction\n",
    "        0.2: 'blue',   # Low density -> blue\n",
    "        0.4: 'green',  # Medium-low density -> green\n",
    "        0.6: 'yellow', # Medium-high density -> yellow\n",
    "        0.8: 'orange', # High density -> orange\n",
    "        1.0: 'red',    # Very high density -> red\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# Create a MarkerCluster for the stops (useful for closely spaced stops)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Define color mapping for passenger counts (using log-transformed values for marker colors)\n",
    "def get_marker_color(log_count):\n",
    "    if log_count < 3.1:   # 0 to 20 passengers\n",
    "        return 'blue'      # Low density -> blue\n",
    "    elif log_count < 5.8:  # 21 to 500 passengers\n",
    "        return 'green'     # Medium density -> green\n",
    "    elif log_count < 6.9:  # 501 to 1000 passengers\n",
    "        return 'orange'    # High density -> orange\n",
    "    else:                  # 1000+ passengers\n",
    "        return 'red'       # Very high density -> red\n",
    "\n",
    "\n",
    "# Add popups and clustered markers for bus stops with their name and transformed passenger count\n",
    "for _, row in stops_df.iterrows():\n",
    "    # Get the color based on the transformed passenger count\n",
    "    color = get_marker_color(row['log_passenger_count'])\n",
    "    \n",
    "    marker = folium.Marker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        popup=f\"<b>{row['stop_name']}</b><br>Passenger count: {row['passenger_count']}<br>Log Transformed: {row['log_passenger_count']:.2f}\",\n",
    "        tooltip=row[\"stop_name\"],\n",
    "        icon=Icon(color=color, icon=\"fa-users\", prefix=\"fa\"),  # Apply color dynamically\n",
    "    )\n",
    "    marker.add_to(marker_cluster)  # Add to MarkerCluster for better organization\n",
    "\n",
    "# Create a legend HTML for color decoding (simplified and smaller)\n",
    "legend_html = '''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 240px; height: 160px; \n",
    "                background-color: white; border: 2px solid grey; padding: 20px; \n",
    "                z-index: 9999; font-size: 10px; border-radius: 8px;\">\n",
    "        <b>Passenger Density Legend</b><br>\n",
    "        <i style=\"background: blue; width: 20px; height: 20px; display: inline-block;\"></i> Low Density (0 - 20 passengers)<br>\n",
    "        <i style=\"background: green; width: 20px; height: 20px; display: inline-block;\"></i> Medium Density (21 - 500 passengers)<br>\n",
    "        <i style=\"background: orange; width: 20px; height: 20px; display: inline-block;\"></i> High Density (501 - 1000 passengers)<br>\n",
    "        <i style=\"background: red; width: 20px; height: 20px; display: inline-block;\"></i> Very High Density (1000+ passengers)\n",
    "    </div>\n",
    "'''\n",
    "\n",
    "# Add the legend to the map\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save map to an HTML file\n",
    "m.save(\"passenger_boarding_density_fff.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
