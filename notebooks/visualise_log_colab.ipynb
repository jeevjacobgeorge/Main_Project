{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install folium==0.18.0"
      ],
      "metadata": {
        "id": "O0ST12NEJmBO",
        "outputId": "7f0db30d-d186-40d5-e88d-72ecbfc0feaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium==0.18.0) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium==0.18.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from folium==0.18.0) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium==0.18.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium==0.18.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium==0.18.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium==0.18.0) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ERd6nhj5AHZP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from pyspark.sql.functions import concat, to_timestamp, col, lit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_GH-LpP9BmP0",
        "outputId": "6bbddd06-0f52-4805-dd17-9bd16ed9550c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/drive/My Drive/KSRTCJune2024.csv\"\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File exists.\")\n",
        "else:\n",
        "    print(\"File does not exist.\")\n"
      ],
      "metadata": {
        "id": "KhyU3yr-DB0q",
        "outputId": "455cef6a-ee18-40df-c69c-b96f5b7564bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qctWtftQAHZQ",
        "outputId": "4ae32a6e-7b2c-4534-81b4-2f43e1cd9da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+-------------------+--------------+---------------+-------------------+----------+--------+-----------+------------+---------+--------------------+--------------------+-----------+-----------+----------+------+---------------+---------------+-------+------------+\n",
            "|          DEPOT_NAME|TICKET_ISSUE_DATE|  TICKET_ISSUE_TIME|WAYBILL_NUMBER|SCHEDULE_NUMBER|       SERVICE_TYPE|ROUTE_NAME|ROUTE_ID|TRIP_NUMBER|          ID|TICKET_NO|      FROM_STOP_NAME|        TO_STOP_NAME|NO_OF_ADULT|NO_OF_CHILD|NO_OF_LUGG|OTHERS|TOTAL_PASSENGER|DISTANCE_TRAVEL|TRIP_KM|PAYMENT_TYPE|\n",
            "+--------------------+-----------------+-------------------+--------------+---------------+-------------------+----------+--------+-----------+------------+---------+--------------------+--------------------+-----------+-----------+----------+------+---------------+---------------+-------+------------+\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 09:03:06|      14146419|  1C 3 Duty 605|           Ordinary|     1614D|cIPyJWNe|          5|100876443615|      191|            Vembayam| East Fort Bus Stand|          2|          0|         0|     0|              2|          19.18|   12.5|        Cash|\n",
            "|    PEROORKADA Depot|       31/05/2024|2024-12-31 09:01:59|      14138653|  3C-1-Duty 401|           Ordinary|3C Magenta|pXrJZCnm|          6|100876440259|      258|             Kowdiar|Thampanoor Main B...|          1|          0|         0|     0|              1|            4.9|   19.5|        Cash|\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 09:02:31|      14146419|  1C 3 Duty 605|           Ordinary|     1614D|cIPyJWNe|          5|100876441886|      190|            Vembayam|         Mannanthala|          1|          0|         0|     0|              1|           9.73|   12.5|        Cash|\n",
            "|    PEROORKADA Depot|       31/05/2024|2024-12-31 09:01:09|      14138723|  3A-1 Duty 405|           Ordinary|3A Magenta|NhhoJAsr|          6|100876437738|      228|   Pattom Sut Office|Thampanoor Railwa...|          1|          0|         0|     0|              1|           3.86|   17.0|        Cash|\n",
            "|    PEROORKADA Depot|       31/05/2024|2024-12-31 09:00:39|      14138653|  3C-1-Duty 401|           Ordinary|3C Magenta|pXrJZCnm|          6|100876436214|      255|             Kowdiar|Thampanoor Main B...|          2|          0|         0|     0|              2|            4.9|   19.5|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 09:02:09|      14155124|        S029021|City Fast Passenger|     1666D|ATeelFYf|          1|100876441240|       93| Sreekaryam Junction|          Aiyroopara|          1|          0|         0|     0|              1|           7.46|   26.2|        Cash|\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 09:01:15|      14142675|  7C-2 Duty 643|           ORDINARY|  7C Green|DwdjjpCJ|          6|100876438194|      408|Palayam Fine Arts...|East Fort South B...|          1|          0|         0|     0|              1|           3.51|   14.5|        Cash|\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 09:00:30|      14147207|  2C-2 Duty 623|           Ordinary|   2C Blue|HhGbDFDa|          5|100876435897|      233|             Pattoor|Vellayambalam Ela...|          1|          0|         0|     0|              1|           3.68|   17.5|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:59:16|      14155908|        S029022|City Fast Passenger|     1666D|ATeelFYf|          1|100876432268|       23|Statue Sbi Or Sec...|          Aiyroopara|          2|          0|         0|     0|              2|          15.58|   26.2|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:53|      14155124|        S029021|City Fast Passenger|     1666D|ATeelFYf|          1|100876431226|       88| Sreekaryam Junction|          Aiyroopara|          1|          0|         0|     0|              1|           7.46|   26.2|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:59:27|      14155124|        S029021|City Fast Passenger|     1666D|ATeelFYf|          1|100876432724|       89| Sreekaryam Junction|        Njadoorkonam|          1|          0|         0|     0|              1|           4.75|   26.2|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:34|      14155124|        S029021|City Fast Passenger|     1666D|ATeelFYf|          1|100876430247|       87| Sreekaryam Junction|          Aiyroopara|          1|          0|         0|     0|              1|           7.46|   26.2|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:38|      14155501|        S029015|City Fast Passenger|     1666A|kpEMaRcK|          1|100876430504|       46|   Pattom Sut Office|      Chenkottukonam|          1|          0|         0|     0|              1|           9.49|   25.0|        Cash|\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 08:59:31|      14142675|  7C-2 Duty 643|           ORDINARY|  7C Green|DwdjjpCJ|          6|100876432581|      407|Palayam Fine Arts...|East Fort South B...|          2|          0|         0|     0|              2|           3.51|   14.5|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:59|      14154954|        S029001|CITY_FAST_PASSENGER|     1650A|NosHvdIV|          1|100876431553|       35|           Kulathoor|       Kazhakkoottam|          1|          0|         0|     0|              1|           3.01|   22.9|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:59|      14155908|        S029022|City Fast Passenger|     1666D|ATeelFYf|          1|100876431517|       22|Statue Sbi Or Sec...|Chellamagalam Pan...|          1|          0|         0|     0|              1|          10.18|   26.2|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:58:08|      14154954|        S029001|CITY_FAST_PASSENGER|     1650A|NosHvdIV|          1|100876431508|       34|           Kulathoor|       Kazhakkoottam|          1|          0|         0|     0|              1|           3.01|   22.9|        Cash|\n",
            "|    PEROORKADA Depot|       31/05/2024|2024-12-31 08:59:58|      14138723|  3A-1 Duty 405|           Ordinary|3A Magenta|NhhoJAsr|          6|100876434026|      226|   Pattom Sut Office|Thampanoor Railwa...|          1|          0|         0|     0|              1|           3.86|   17.0|        Cash|\n",
            "|  VIKAS BHAVAN Depot|       31/05/2024|2024-12-31 08:59:22|      14155501|        S029015|City Fast Passenger|     1666A|kpEMaRcK|          1|100876432573|       47|   Pattom Sut Office|          Pothencode|          1|          0|         0|     0|              1|          13.84|   25.0|        Cash|\n",
            "|TRIVANDRUM CITY D...|       31/05/2024|2024-12-31 08:59:11|      14142675|  7C-2 Duty 643|           ORDINARY|  7C Green|DwdjjpCJ|          6|100876431756|      405|Palayam Fine Arts...|East Fort South B...|          1|          0|         0|     0|              1|           3.51|   14.5|        Cash|\n",
            "+--------------------+-----------------+-------------------+--------------+---------------+-------------------+----------+--------+-----------+------------+---------+--------------------+--------------------+-----------+-----------+----------+------+---------------+---------------+-------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import sum as spark_sum, col, hour, concat_ws, to_date, date_format\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Initialize a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BigDataProcessing\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 2: Load your CSV file from Google Drive into a Spark DataFrame\n",
        "file_path = \"/content/drive/My Drive/June2024.csv\"\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "# Step 3: Perform operations on the DataFrame\n",
        "data.show()  # Display the first few rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yRD221n4AHZR"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# Define the specific time range\n",
        "start_time = \"12:45:00\"\n",
        "end_time = \"14:45:00\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mr-Gn03UAHZR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_timestamp, concat, col, lit, date_format, expr\n",
        "# Filter rows where ROUTE_ID is 'acwXkRFM'\n",
        "# data = data.filter(col(\"ROUTE_ID\") == 'acwXkRFM')\n",
        "# Step 2: Format TICKET_ISSUE_TIME as a string in \"HH:mm:ss\" format (if not already) and combine date and time\n",
        "\n",
        "data = data.withColumn(\"TICKET_ISSUE_TIME_STR\", date_format(col(\"TICKET_ISSUE_TIME\"), \"HH:mm:ss\"))\n",
        "# Filter rows within the specific time range\n",
        "# Show data which has time other than start_time and end_time\n",
        "\n",
        "data = data.filter((col(\"TICKET_ISSUE_TIME_STR\") >= start_time) & (col(\"TICKET_ISSUE_TIME_STR\") <= end_time))\n",
        "# Calculate the total number of days in the dataset\n",
        "total_days = data.select(to_date(col(\"TICKET_ISSUE_DATE\")).alias(\"date\")).distinct().count()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A3T6z3MPAHZR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "import folium\n",
        "import pandas as pd\n",
        "from geopy.geocoders import Nominatim\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "LIMIT_OF_TOP_BUS_STOPS = 600\n",
        "MIN_AVG_THRESHOLD = 5\n",
        "# Aggregate data to get total passenger count per bus stop within the time range\n",
        "# Sort by total passengers in descending order and select the top 20\n",
        "top_bus_stops = (\n",
        "    data.groupBy(\"FROM_STOP_NAME\")\n",
        "    .agg(F.sum(\"TOTAL_PASSENGER\").alias(\"TOTAL_PASSENGER\"))\n",
        "    .withColumn(\"AVERAGE_PASSENGER\", F.col(\"TOTAL_PASSENGER\") / total_days)\n",
        "    .filter(F.col(\"AVERAGE_PASSENGER\") >= MIN_AVG_THRESHOLD)\n",
        "    .orderBy(\"TOTAL_PASSENGER\", ascending=False)\n",
        "    .limit(LIMIT_OF_TOP_BUS_STOPS)\n",
        "    .collect()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save geocoded data to a JSON file\n",
        "def save_geocoded_data(data):\n",
        "    with open(GEO_CACHE_FILE, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "# Function to check if a location is in South India\n",
        "def is_in_south_india(latitude, longitude):\n",
        "    return (SOUTH_INDIA_LAT_MIN <= latitude <= SOUTH_INDIA_LAT_MAX) and (SOUTH_INDIA_LON_MIN <= longitude <= SOUTH_INDIA_LON_MAX)\n",
        "\n",
        "def load_geocoded_failures():\n",
        "    try:\n",
        "        with open(FAILURE_CACHE_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {}"
      ],
      "metadata": {
        "id": "5wt3hZ7BGo05"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lauc4oLGAHZR",
        "outputId": "3049b985-8617-4586-9397-a97d18e77a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[======================================= ] 100.0%\n",
            "Geocoding Successes: 361\n",
            "Geocoding Failures: 212\n",
            "Failed to geocode the following bus stops:\n",
            "['East Fort North Bus Stand', 'Thampanoor Main Bus Stand', 'East South Fort Bus Stand', 'Pattom Sut Office', 'East Fort South Bus Stand', 'Statue Sbi Or Secretariat', 'Statue Sbi (outside South India)', 'World Market (outside South India)', 'Venjarammoodu Depot', 'Karamana Junction', 'Chakai (outside South India)', 'Vellayambalam Elankim Devi', 'Shangumukham Beach', 'Sree Karyam', 'Rotary (outside South India)', 'Kseb Chakkai', 'Shangumukham', 'Njadoorkonam', 'Radio Station Monvila', 'Valiyathura Shangumugam', '16th Mile (outside South India)', 'Chellamagalam Panjayath', 'Vizhinjam Bus Stand', 'Beema Pally', 'Crpf Gate', 'Mamam (outside South India)', 'Thrikkannapuram (outside South India)', 'Korani Junction', 'Technopark Front Gate', 'Venjarammoodu', 'Agricultural College Poonkulam', 'Mananthala (outside South India)', 'Sainik School (outside South India)', 'Veli Church (outside South India)', 'Titanium (outside South India)', 'Saraswathy Vidyalaya School (outside South India)', 'Killy (outside South India)', 'Azhikode (outside South India)', 'Maithani (outside South India)', 'East Fort North Bus Stand Pf 2', 'Statue (outside South India)', 'Karipur (outside South India)', 'Museum (outside South India)', 'Koduganoor', 'St Andrews (outside South India)', 'Punkumood', 'Punnakkamugal Junction', 'Vazhayila Paalam', 'Pwodeesyaram Society Muku', 'Villant (outside South India)', 'Thachottukavu Junction', 'Chathanoor Ksrtc Depot', 'Bakery Junction (outside South India)', 'Civil Station Gate', 'Karingadamugal', 'Murinjapalam Vengode', 'Contonment Gate', 'Kuttiyani Lps', 'Aruvikkara Hs', 'Seematty', 'Venjaramoodu Depot', 'Vazhayila Pally', '28th Mile (outside South India)', 'Scooter Factory (outside South India)', 'Mankattumoola', 'Poomalliyoorkonam', 'Iti Chakai', 'Madhapuram Crasher', 'Kukkil Kada', 'Aliyeltharatta', 'Enikkara Haritha Market', 'Plamood Pothencode', 'Sasthan Kovil', 'Jala Vijnana Bhavan', 'Menilam Library', 'Pirambilkonam', 'Aazhakulam', 'Radio Park Junction', 'Aramada (outside South India)', 'Kanjirampara Jn', 'Bhagat Singh Road (outside South India)', 'Lords (outside South India)', 'Ambalathinkara Palli', 'Chathenpra', 'Government Lp School Marayamuttom', 'Kurisadi Junction Karyavattom', 'Chittalloor Temple', 'Fci (outside South India)', 'Kalloor Palam', \"St Joseph's School Muttada\", 'Kunnapuzha Lps', 'Nalanchira Kurishadi', 'J T S Mancha (outside South India)', 'Alumuttu', 'Arattukuzhi', 'Mannanthala High School', 'Thiruvallom School', 'Pongode', 'Vellaripana', 'Pump House (outside South India)', 'Sptpm Government Up School', 'Urban P H C Muttada', 'Lbs Institute Poojappura', 'Thellikkachal', 'Kaduvakkuzhy', 'Chiramykku', 'Oonnampara', 'Government Taluk Hospital Santhivila', 'Panthalakode Junction', 'Charachira Pally', 'Lulu Mall (outside South India)', 'Punnkka Thope', 'Kanakkod (outside South India)', 'Punthankada', 'Doordarshan (outside South India)', 'Koottappara (outside South India)', 'Concordia Lutheran High School (outside South India)', 'Kodukunnu Palli Or Puthukunnu Church', 'Moonnanakuzhi', 'Concordia School (outside South India)', 'Chenkottukonam Flat', 'Cherappally', 'St Thomas Mukkolakkal']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "from geopy.geocoders import Nominatim\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Latitude and Longitude bounds for South India\n",
        "SOUTH_INDIA_LAT_MIN = 8.0\n",
        "SOUTH_INDIA_LAT_MAX = 14.5\n",
        "SOUTH_INDIA_LON_MIN = 76.0\n",
        "SOUTH_INDIA_LON_MAX = 85.0\n",
        "\n",
        "# File to store previously geocoded bus stops\n",
        "GEO_CACHE_FILE = '/content/drive/My Drive/geocoded_stops.json'\n",
        "FAILURE_CACHE_FILE = '/content/drive/My Drive/geocoding_failures.json'\n",
        "\n",
        "# Function to load previously cached geocoded data from a JSON file\n",
        "def load_geocoded_data():\n",
        "    try:\n",
        "        with open(GEO_CACHE_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n",
        "# Prepare data for geocoding (replace 'top_bus_stops' with your actual data)\n",
        "bus_stops_data = [{\"stop_name\": row[\"FROM_STOP_NAME\"], \"passenger_count\": row[\"AVERAGE_PASSENGER\"]} for row in top_bus_stops]\n",
        "\n",
        "# Initialize the geocoder\n",
        "geolocator = Nominatim(user_agent=\"bus_stop_locator\")\n",
        "\n",
        "# Load previously geocoded data from the cache\n",
        "cached_data = load_geocoded_data()\n",
        "cached_failure_data = load_geocoded_failures()\n",
        "\n",
        "# Initialize counters for success and failure\n",
        "success_count = 0\n",
        "failure_count = 0\n",
        "failures = []\n",
        "\n",
        "# Function to print the progress bar\n",
        "def print_progress_bar(iteration, total, bar_length=40):\n",
        "    progress = iteration / total\n",
        "    arrow = '=' * int(round(progress * bar_length) - 1)\n",
        "    spaces = ' ' * (bar_length - len(arrow))\n",
        "    percent = round(progress * 100, 1)\n",
        "    sys.stdout.write(f'\\r[{arrow}{spaces}] {percent}%')\n",
        "    sys.stdout.flush()\n",
        "\n",
        "# Geocode each bus stop with exponential backoff\n",
        "for i, stop in enumerate(bus_stops_data):\n",
        "    stop_name = stop[\"stop_name\"]\n",
        "\n",
        "    # Skip if the stop is in the failures list\n",
        "    if stop_name in cached_data:\n",
        "        # Use cached data\n",
        "        stop[\"latitude\"] = cached_data[stop_name][\"latitude\"]\n",
        "        stop[\"longitude\"] = cached_data[stop_name][\"longitude\"]\n",
        "        success_count += 1  # Increment success count for cached data\n",
        "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
        "        continue  # Skip geocoding since it's already cached\n",
        "    elif stop_name in cached_failure_data:\n",
        "        # Skip geocoding if it previously failed\n",
        "        failure_count += 1\n",
        "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
        "        continue\n",
        "\n",
        "    # If not cached, geocode this stop\n",
        "    retries = 0  # Counter for retry attempts\n",
        "    while retries < 2:\n",
        "        try:\n",
        "            # Geocode the stop with a timeout\n",
        "            location = geolocator.geocode(stop_name, timeout=20)\n",
        "\n",
        "            if location:\n",
        "                latitude = location.latitude\n",
        "                longitude = location.longitude\n",
        "\n",
        "                # Check if the coordinates are within South India's bounds\n",
        "                if is_in_south_india(latitude, longitude):\n",
        "                    stop[\"latitude\"] = latitude\n",
        "                    stop[\"longitude\"] = longitude\n",
        "                    # Save the geocoded result in the cache\n",
        "                    cached_data[stop_name] = {\"latitude\": stop[\"latitude\"], \"longitude\": stop[\"longitude\"]}\n",
        "                    success_count += 1  # Increment success count\n",
        "                else:\n",
        "                    # If outside South India, mark as None\n",
        "                    stop[\"latitude\"] = None\n",
        "                    stop[\"longitude\"] = None\n",
        "                    failure_count += 1  # Increment failure count\n",
        "                    failures.append(f\"{stop_name} (outside South India)\")\n",
        "            else:\n",
        "                stop[\"latitude\"] = None\n",
        "                stop[\"longitude\"] = None\n",
        "                failure_count += 1  # Increment failure count\n",
        "                failures.append(stop_name)\n",
        "\n",
        "            break  # Exit the retry loop on success\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            print(f\"Error geocoding {stop_name}: {e}\")\n",
        "            stop[\"latitude\"] = None\n",
        "            stop[\"longitude\"] = None\n",
        "            failures.append(stop_name)\n",
        "            failure_count += 1  # Increment failure count\n",
        "\n",
        "            # Exponential backoff\n",
        "            backoff_time = min(2 ** retries + random.uniform(0, 1), 30)  # max backoff of 30 seconds\n",
        "            print(f\"Retrying {stop_name} in {backoff_time:.2f} seconds...\")\n",
        "            time.sleep(backoff_time)  # Sleep exponentially between retries\n",
        "\n",
        "    # If retries are exhausted, skip to the next stop\n",
        "    if retries == 2:\n",
        "        print(f\"Failed to geocode {stop_name} after {retries} retries.\")\n",
        "\n",
        "    # Update progress bar\n",
        "    print_progress_bar(i + 1, len(bus_stops_data))\n",
        "\n",
        "# Save the updated geocoded data to the cache file\n",
        "save_geocoded_data(cached_data)\n",
        "\n",
        "# Output the number of successes and failures\n",
        "print(f\"\\nGeocoding Successes: {success_count}\")\n",
        "print(f\"Geocoding Failures: {failure_count}\")\n",
        "if failures:\n",
        "    print(\"Failed to geocode the following bus stops:\")\n",
        "    print(failures)\n",
        "\n",
        "    # Function to save geocoding failures to a JSON file\n",
        "    def save_geocoding_failures(failures):\n",
        "        with open(FAILURE_CACHE_FILE, 'w') as f:\n",
        "            json.dump(failures, f, indent=4)\n",
        "\n",
        "    # Save the geocoding failures to the cache file\n",
        "    save_geocoding_failures(failures)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sMV16JaWAHZS",
        "outputId": "46d534c8-c7a6-48da-b937-8019996f365e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<branca.element.Element at 0x7a3be516a860>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from folium.plugins import HeatMap\n",
        "import folium\n",
        "import pandas as pd\n",
        "from folium import Icon\n",
        "from folium.plugins import MarkerCluster\n",
        "import numpy as np\n",
        "\n",
        "# Filter out stops without coordinates\n",
        "stops_with_coords = [stop for stop in bus_stops_data if 'latitude' in stop and 'longitude' in stop and stop[\"latitude\"] is not None and stop[\"longitude\"] is not None]\n",
        "\n",
        "# Convert to Pandas DataFrame for easier handling with Folium\n",
        "stops_df = pd.DataFrame(stops_with_coords)\n",
        "\n",
        "# Initialize a Folium map centered around an average location\n",
        "map_center = [8.4869, 76.9529]\n",
        "m = folium.Map(location=map_center, tiles=\"CartoDB positron\", zoom_start=13, min_zoom=8, max_zoom=18)\n",
        "\n",
        "# Logarithmic transformation of passenger counts for better contrast in markers\n",
        "stops_df['log_passenger_count'] = np.log1p(stops_df['passenger_count'])\n",
        "\n",
        "# Prepare data for HeatMap using actual passenger counts for intensity\n",
        "heat_data = []\n",
        "for _, row in stops_df.iterrows():\n",
        "    heat_data.append([row[\"latitude\"], row[\"longitude\"], row[\"passenger_count\"]])  # Using actual count for heatmap\n",
        "\n",
        "# Create the HeatMap layer with adjusted visual settings\n",
        "HeatMap(\n",
        "    heat_data,\n",
        "    min_opacity=0.3,  # Set minimum opacity for better visibility (not too faint)\n",
        "    max_opacity=0.7,  # Set maximum opacity for a more subtle heatmap\n",
        "    radius=25,        # Adjust radius size to balance between clarity and overlap\n",
        "    blur=18,          # Moderate blur to avoid excessive smoothing\n",
        "    gradient={        # Reduced 5-color gradient scale for better distinction\n",
        "        0.2: 'blue',   # Low density -> blue\n",
        "        0.4: 'green',  # Medium-low density -> green\n",
        "        0.6: 'yellow', # Medium-high density -> yellow\n",
        "        0.8: 'orange', # High density -> orange\n",
        "        1.0: 'red',    # Very high density -> red\n",
        "    }\n",
        ").add_to(m)\n",
        "\n",
        "# Create a MarkerCluster for the stops (useful for closely spaced stops)\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "# Define color mapping for passenger counts (using log-transformed values for marker colors)\n",
        "def get_marker_color(log_count):\n",
        "    if log_count < 3.1:   # 0 to 20 passengers\n",
        "        return 'blue'      # Low density -> blue\n",
        "    elif log_count < 5.8:  # 21 to 500 passengers\n",
        "        return 'green'     # Medium density -> green\n",
        "    elif log_count < 6.9:  # 501 to 1000 passengers\n",
        "        return 'orange'    # High density -> orange\n",
        "    else:                  # 1000+ passengers\n",
        "        return 'red'       # Very high density -> red\n",
        "\n",
        "\n",
        "# Add popups and clustered markers for bus stops with their name and transformed passenger count\n",
        "for _, row in stops_df.iterrows():\n",
        "    # Get the color based on the transformed passenger count\n",
        "    color = get_marker_color(row['log_passenger_count'])\n",
        "\n",
        "    marker = folium.Marker(\n",
        "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
        "        popup=f\"<b>{row['stop_name']}</b><br>Passenger count: {row['passenger_count']}<br>Log Transformed: {row['log_passenger_count']:.2f}\",\n",
        "        tooltip=row[\"stop_name\"],\n",
        "        icon=Icon(color=color, icon=\"fa-users\", prefix=\"fa\"),  # Apply color dynamically\n",
        "    )\n",
        "    marker.add_to(marker_cluster)  # Add to MarkerCluster for better organization\n",
        "\n",
        "# Create a legend HTML for color decoding (simplified and smaller)\n",
        "legend_html = '''\n",
        "    <div style=\"position: fixed;\n",
        "                bottom: 50px; left: 50px; width: 240px; height: 160px;\n",
        "                background-color: white; border: 2px solid grey; padding: 20px;\n",
        "                z-index: 9999; font-size: 10px; border-radius: 8px;\">\n",
        "        <b>Passenger Density Legend</b><br>\n",
        "        <i style=\"background: blue; width: 20px; height: 20px; display: inline-block;\"></i> Low Density (0 - 20 passengers)<br>\n",
        "        <i style=\"background: green; width: 20px; height: 20px; display: inline-block;\"></i> Medium Density (21 - 500 passengers)<br>\n",
        "        <i style=\"background: orange; width: 20px; height: 20px; display: inline-block;\"></i> High Density (501 - 1000 passengers)<br>\n",
        "        <i style=\"background: red; width: 20px; height: 20px; display: inline-block;\"></i> Very High Density (1000+ passengers)\n",
        "    </div>\n",
        "'''\n",
        "\n",
        "# Add the legend to the map\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the map to Google Drive\n",
        "save_path = '/content/drive/My Drive/passenger_boarding_density_map.html'\n",
        "m.save(save_path)\n",
        "\n",
        "print(f\"Map saved successfully to {save_path}\")"
      ],
      "metadata": {
        "id": "VNELcg90KNZd",
        "outputId": "63866cb2-4952-4872-81fe-537962085341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map saved successfully to /content/drive/My Drive/passenger_boarding_density_map.html\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}