{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pyspark.sql.functions import concat, to_timestamp, col, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Define the specific time range\n",
    "start_time = \"12:45:00\"\n",
    "end_time = \"13:45:00\"\n",
    "month = \"june\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data loaded successfully.\n",
      "DataFrame[TICKET_ISSUE_DATE: string, TICKET_ISSUE_TIME: timestamp, FROM_STOP_NAME: string, TO_STOP_NAME: string, TOTAL_PASSENGER: int, ROUTE_NAME: string, NO_OF_ADULT: int, NO_OF_CHILD: int]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.                         (0 + 8) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o89.count",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfilter((col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTICKET_ISSUE_TIME_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start_time) \u001b[38;5;241m&\u001b[39m (col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTICKET_ISSUE_TIME_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_time))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate the total number of days in the dataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m total_days \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTICKET_ISSUE_DATE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistinct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m total_days \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/dataframe.py:1240\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o89.count"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/jeev/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import sum as spark_sum, col, hour, concat_ws, to_date, date_format\n",
    "from pyspark.sql.functions import to_timestamp, concat, col, lit, date_format, expr\n",
    "# Stop any existing Spark sessions to avoid conflicts\n",
    "if SparkSession._instantiatedSession:\n",
    "    SparkSession._instantiatedSession.stop()\n",
    "\n",
    "# Step 1: Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataProcessing\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load your CSV file into a Spark DataFrame\n",
    "try:\n",
    "    data = spark.read.csv(\"filtered_\"+month+\".csv\", header=True, inferSchema=True)\n",
    "    print(\"CSV data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    spark.stop()\n",
    "    raise  # Stop the script if loading fails\n",
    "\n",
    "\n",
    "# Filter rows where ROUTE_ID is 'acwXkRFM'\n",
    "# data = data.filter(col(\"ROUTE_ID\") == 'acwXkRFM')\n",
    "# Step 2: Format TICKET_ISSUE_TIME as a string in \"HH:mm:ss\" format (if not already) and combine date and time\n",
    "print(data)\n",
    "data = data.withColumn(\"TICKET_ISSUE_TIME_STR\", date_format(col(\"TICKET_ISSUE_TIME\"), \"HH:mm:ss\"))\n",
    "# Filter rows within the specific time range\n",
    "# Show data which has time other than start_time and end_time\n",
    "\n",
    "data = data.filter((col(\"TICKET_ISSUE_TIME_STR\") >= start_time) & (col(\"TICKET_ISSUE_TIME_STR\") <= end_time))\n",
    "# Calculate the total number of days in the dataset\n",
    "total_days = data.select(countDistinct(\"TICKET_ISSUE_DATE\")).collect()[0][0]\n",
    "total_days \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LIMIT_OF_TOP_BUS_STOPS = 600\n",
    "MIN_AVG_THRESHOLD = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import folium\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "\n",
    "# Aggregate data to get total passenger count per bus stop within the time range\n",
    "# Sort by total passengers in descending order and select the top 20\n",
    "top_bus_stops = (\n",
    "    data.groupBy(\"FROM_STOP_NAME\")\n",
    "    .agg(F.sum(\"TOTAL_PASSENGER\").alias(\"TOTAL_PASSENGER\"))\n",
    "    .withColumn(\"AVERAGE_PASSENGER\", F.col(\"TOTAL_PASSENGER\") / total_days)\n",
    "    .filter(F.col(\"AVERAGE_PASSENGER\") >= MIN_AVG_THRESHOLD)\n",
    "    .orderBy(\"TOTAL_PASSENGER\", ascending=False)\n",
    "    .limit(LIMIT_OF_TOP_BUS_STOPS)\n",
    "    .collect()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stop the Spark session at the end\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================= ] 100.0%\n",
      "Geocoding Successes: 303\n",
      "Geocoding Failures: 166\n",
      "Failed to geocode the following bus stops:\n",
      "['Statue Sbi (outside South India)', 'Chakai (outside South India)', 'World Market (outside South India)', 'Easwara Vilasam Cotton Hill School', 'Rotary (outside South India)', 'Mangalapuram East', '16th Mile (outside South India)', 'Aiyroopara', 'Civil Station Junction Kudappanakunnu', 'Mamam (outside South India)', 'Pullampara Palam', 'Panangodu Junction', 'Edapazhanji Pangode Fish Market', 'Kachani Junction', 'Kalliyoor Grama Panchayath Office', 'Vellarada Ksrtc Depot', 'Thekkada Junction', 'Beemapalli Back', 'East Mukkola', 'Kazhakkoottam Railway Station', 'Kudappanakunnu Bank Junction', 'Pettah Pallimukku Junction', 'Mananthala (outside South India)', 'Titanium (outside South India)', 'Irinchayam Steps', 'Puthukurichi Post Office', 'Sainik School (outside South India)', 'Mithrumala', 'Kanjirampara Junction', 'St Andrews (outside South India)', 'Punchakkari', 'Kottarakkari', 'Kayalkara', 'Vazhavilapaalam', 'Kattadimukku', 'Water Tank Pallithura', 'Poovanathin Moodu', 'Thrikkannapuram (outside South India)', 'Chempoor Junction', 'Puthiyathura Junction', '6th Stone Vazhayila', 'Oorambu', 'Pazhayakada Junction', 'Irumpa', 'Block Junction Venkavila', 'Poovar Junction', 'Museum (outside South India)', 'Military Hospital Pangodu', 'Vamanapuram Phc', 'Venkavila Junction', 'Chadayamangalam Bus Stand', 'Pezhummoodu Junction', 'Vavara Ambalam', 'Veli Church (outside South India)', 'Thumpod', 'Cheru Vettukadu', 'Karipur (outside South India)', 'Paruthikkuzhy', 'Chenkavila Junction', 'East Fort South Stand 2', 'Olathanni Junction', 'Maithani (outside South India)', 'Channakara', 'Pappanchani Junction', 'Postoffice Junction Parassala', 'Arumanior Junction', 'Vandannur', 'Pachaloor Chudukadu Temple', 'Ks Road Kovalam Junction', 'Meenakal', 'Narmadha Toll Junction', 'Melathumele', 'Mele Aramthanam', 'Valliya Kattayikkal', 'Madhupalam', 'Government Lp School Marayamuttom', 'Ookkodu', 'Seematty', 'Konkalam Junction', 'Pozhiyoor Junction', 'Pulinkudy', 'Chettikulangara Sreedevi Temple', 'J T S Mancha (outside South India)', 'Malayam High School', 'Nannattukavu A', 'Puthuveettumele', 'Killy (outside South India)', 'Post Office Manivila', 'Radio Park Junction', 'Karikkakom Vayanasala', 'Kalliyodu', 'Bakery Junction (outside South India)', '10th Stone Patham Kallu', 'Chalakuzhy', 'Vithura Kalung Junction', 'Concordia Lutheran High School (outside South India)', 'Chittalloor Temple', 'Villant (outside South India)', 'Azhikode (outside South India)', 'Scooter Factory (outside South India)', 'Amaravila Thannimoodu', '28th Mile (outside South India)', 'Technopark Front Gate', 'Karumom Vishnu Temple', 'Government Press Mannanthala', 'Devi Nagar (outside South India)', 'Chekkalamukku', 'Iti Chakai', 'Medical College Sat', 'Arattukuzhi', 'Punnakkamugal Junction', 'Aramada (outside South India)', 'Urban P H C Muttada', 'Nilama (outside South India)', 'Aramada Good Shepherd', 'Chadayamankalam', 'Vellumannady Palam', 'Chengalloor Hll', 'Poomalliyoorkonam', 'Bhagat Singh Road (outside South India)', 'Madathikonam', 'Vallamcode Junction', 'Pannimala', 'Thiruvallom School', 'Perunelli', 'Thekkada Stpes', 'Pachira (outside South India)', 'Sree Chithra Medical College', 'Aruvattukonam Point', 'Muthalapozhi Palam', 'Alumuttu', 'Pammathikeezhu', 'Koothali (outside South India)', 'Near Mannammoola Palam', 'Technical H S S (outside South India)', \"St Joseph's School Muttada\", 'Panagod', 'Muttada St Joseph School', 'Pazhaya Mukkola Or Mananthala East', 'Oonnampara', 'Kulappada Market/eliyavoor', 'Fci (outside South India)', 'Mele Venchavode Or Imb Hospital']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Latitude and Longitude bounds for South India\n",
    "SOUTH_INDIA_LAT_MIN = 8.0\n",
    "SOUTH_INDIA_LAT_MAX = 14.0\n",
    "SOUTH_INDIA_LON_MIN = 76.0\n",
    "SOUTH_INDIA_LON_MAX = 80.0\n",
    "\n",
    "# File to store previously geocoded bus stops\n",
    "GEO_CACHE_FILE = 'geocoded_stops.json'\n",
    "FAILURE_CACHE_FILE = 'geocoding_failures.json'\n",
    "\n",
    "# Function to load previously cached geocoded data from a JSON file\n",
    "def load_geocoded_data():\n",
    "    try:\n",
    "        with open(GEO_CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Function to save geocoded data to a JSON file\n",
    "def save_geocoded_data(data):\n",
    "    with open(GEO_CACHE_FILE, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Function to check if a location is in South India\n",
    "def is_in_south_india(latitude, longitude):\n",
    "    return (SOUTH_INDIA_LAT_MIN <= latitude <= SOUTH_INDIA_LAT_MAX) and (SOUTH_INDIA_LON_MIN <= longitude <= SOUTH_INDIA_LON_MAX)\n",
    "\n",
    "def load_geocoded_failures():\n",
    "    try:\n",
    "        with open(FAILURE_CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "# Prepare data for geocoding (replace 'top_bus_stops' with your actual data)\n",
    "bus_stops_data = [{\"stop_name\": row[\"FROM_STOP_NAME\"], \"passenger_count\": row[\"AVERAGE_PASSENGER\"]} for row in top_bus_stops]\n",
    "\n",
    "# Initialize the geocoder\n",
    "geolocator = Nominatim(user_agent=\"bus_stop_locator\")\n",
    "\n",
    "# Load previously geocoded data from the cache\n",
    "cached_data = load_geocoded_data()\n",
    "cached_failure_data = load_geocoded_failures()\n",
    "\n",
    "# Initialize counters for success and failure\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "failures = []\n",
    "\n",
    "# Function to print the progress bar\n",
    "def print_progress_bar(iteration, total, bar_length=40):\n",
    "    progress = iteration / total\n",
    "    arrow = '=' * int(round(progress * bar_length) - 1)\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    percent = round(progress * 100, 1)\n",
    "    sys.stdout.write(f'\\r[{arrow}{spaces}] {percent}%')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Geocode each bus stop with exponential backoff\n",
    "for i, stop in enumerate(bus_stops_data):\n",
    "    stop_name = stop[\"stop_name\"]\n",
    "    \n",
    "    # Skip if the stop is in the failures list\n",
    "    if stop_name in cached_data:\n",
    "        # Use cached data\n",
    "        stop[\"latitude\"] = cached_data[stop_name][\"latitude\"]\n",
    "        stop[\"longitude\"] = cached_data[stop_name][\"longitude\"]\n",
    "        success_count += 1  # Increment success count for cached data\n",
    "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
    "        continue  # Skip geocoding since it's already cached\n",
    "    elif stop_name in cached_failure_data:\n",
    "        # Skip geocoding if it previously failed\n",
    "        failure_count += 1\n",
    "        print_progress_bar(i + 1, len(bus_stops_data))  # Update progress bar for this stop\n",
    "        continue\n",
    "\n",
    "    # If not cached, geocode this stop\n",
    "    retries = 0  # Counter for retry attempts\n",
    "    while retries < 2:\n",
    "        try:\n",
    "            # Geocode the stop with a timeout\n",
    "            location = geolocator.geocode(stop_name, timeout=20)\n",
    "\n",
    "            if location:\n",
    "                latitude = location.latitude\n",
    "                longitude = location.longitude\n",
    "\n",
    "                # Check if the coordinates are within South India's bounds\n",
    "                if is_in_south_india(latitude, longitude):\n",
    "                    stop[\"latitude\"] = latitude\n",
    "                    stop[\"longitude\"] = longitude\n",
    "                    # Save the geocoded result in the cache\n",
    "                    cached_data[stop_name] = {\"latitude\": stop[\"latitude\"], \"longitude\": stop[\"longitude\"]}\n",
    "                    success_count += 1  # Increment success count\n",
    "                else:\n",
    "                    # If outside South India, mark as None\n",
    "                    stop[\"latitude\"] = None\n",
    "                    stop[\"longitude\"] = None\n",
    "                    failure_count += 1  # Increment failure count\n",
    "                    failures.append(f\"{stop_name} (outside South India)\")\n",
    "            else:\n",
    "                stop[\"latitude\"] = None\n",
    "                stop[\"longitude\"] = None\n",
    "                failure_count += 1  # Increment failure count\n",
    "                failures.append(stop_name)\n",
    "\n",
    "            break  # Exit the retry loop on success\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            print(f\"Error geocoding {stop_name}: {e}\")\n",
    "            stop[\"latitude\"] = None\n",
    "            stop[\"longitude\"] = None\n",
    "            failures.append(stop_name)\n",
    "            failure_count += 1  # Increment failure count\n",
    "\n",
    "            # Exponential backoff\n",
    "            backoff_time = min(2 ** retries + random.uniform(0, 1), 30)  # max backoff of 30 seconds\n",
    "            print(f\"Retrying {stop_name} in {backoff_time:.2f} seconds...\")\n",
    "            time.sleep(backoff_time)  # Sleep exponentially between retries\n",
    "\n",
    "    # If retries are exhausted, skip to the next stop\n",
    "    if retries == 2:\n",
    "        print(f\"Failed to geocode {stop_name} after {retries} retries.\")\n",
    "    \n",
    "    # Update progress bar\n",
    "    print_progress_bar(i + 1, len(bus_stops_data))\n",
    "\n",
    "# Save the updated geocoded data to the cache file\n",
    "save_geocoded_data(cached_data)\n",
    "\n",
    "# Output the number of successes and failures\n",
    "print(f\"\\nGeocoding Successes: {success_count}\")\n",
    "print(f\"Geocoding Failures: {failure_count}\")\n",
    "if failures:\n",
    "    print(\"Failed to geocode the following bus stops:\")\n",
    "    print(failures)\n",
    "\n",
    "    # Function to save geocoding failures to a JSON file\n",
    "    def save_geocoding_failures(failures):\n",
    "        with open(FAILURE_CACHE_FILE, 'w') as f:\n",
    "            json.dump(failures, f, indent=4)\n",
    "\n",
    "    # Save the geocoding failures to the cache file\n",
    "    save_geocoding_failures(failures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<branca.element.Element at 0x7fe3eee86da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folium.plugins import HeatMap\n",
    "import folium\n",
    "import pandas as pd\n",
    "from folium import Icon\n",
    "from folium.plugins import MarkerCluster\n",
    "import numpy as np\n",
    "\n",
    "# Filter out stops without coordinates\n",
    "stops_with_coords = [stop for stop in bus_stops_data if 'latitude' in stop and 'longitude' in stop and stop[\"latitude\"] is not None and stop[\"longitude\"] is not None]\n",
    "\n",
    "# Convert to Pandas DataFrame for easier handling with Folium\n",
    "stops_df = pd.DataFrame(stops_with_coords)\n",
    "\n",
    "# Initialize a Folium map centered around an average location\n",
    "map_center = [8.4869, 76.9529]\n",
    "m = folium.Map(location=map_center, tiles=\"CartoDB positron\", zoom_start=13, min_zoom=8, max_zoom=18)\n",
    "\n",
    "# Logarithmic transformation of passenger counts for better contrast in markers\n",
    "stops_df['log_passenger_count'] = np.log1p(stops_df['passenger_count'])\n",
    "\n",
    "# Prepare data for HeatMap using actual passenger counts for intensity\n",
    "heat_data = []\n",
    "for _, row in stops_df.iterrows():\n",
    "    heat_data.append([row[\"latitude\"], row[\"longitude\"], row[\"passenger_count\"]])  # Using actual count for heatmap\n",
    "\n",
    "# Create the HeatMap layer with adjusted visual settings\n",
    "HeatMap(\n",
    "    heat_data,\n",
    "    min_opacity=0.3,  # Set minimum opacity for better visibility (not too faint)\n",
    "    max_opacity=0.7,  # Set maximum opacity for a more subtle heatmap\n",
    "    radius=25,        # Adjust radius size to balance between clarity and overlap\n",
    "    blur=18,          # Moderate blur to avoid excessive smoothing\n",
    "    gradient={        # Reduced 5-color gradient scale for better distinction\n",
    "        0.2: 'blue',   # Low density -> blue\n",
    "        0.4: 'green',  # Medium-low density -> green\n",
    "        0.6: 'yellow', # Medium-high density -> yellow\n",
    "        0.8: 'orange', # High density -> orange\n",
    "        1.0: 'red',    # Very high density -> red\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# Create a MarkerCluster for the stops (useful for closely spaced stops)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Define color mapping for passenger counts (using log-transformed values for marker colors)\n",
    "def get_marker_color(log_count):\n",
    "    if log_count < 3.1:   # 0 to 20 passengers\n",
    "        return 'blue'      # Low density -> blue\n",
    "    elif log_count < 5.8:  # 21 to 500 passengers\n",
    "        return 'green'     # Medium density -> green\n",
    "    elif log_count < 6.9:  # 501 to 1000 passengers\n",
    "        return 'orange'    # High density -> orange\n",
    "    else:                  # 1000+ passengers\n",
    "        return 'red'       # Very high density -> red\n",
    "\n",
    "\n",
    "# Add popups and clustered markers for bus stops with their name and transformed passenger count\n",
    "for _, row in stops_df.iterrows():\n",
    "    # Get the color based on the transformed passenger count\n",
    "    color = get_marker_color(row['log_passenger_count'])\n",
    "    \n",
    "    marker = folium.Marker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        popup=f\"<b>{row['stop_name']}</b><br>Passenger count: {row['passenger_count']}<br>Log Transformed: {row['log_passenger_count']:.2f}\",\n",
    "        tooltip=row[\"stop_name\"],\n",
    "        icon=Icon(color=color, icon=\"fa-users\", prefix=\"fa\"),  # Apply color dynamically\n",
    "    )\n",
    "    marker.add_to(marker_cluster)  # Add to MarkerCluster for better organization\n",
    "\n",
    "# Create a legend HTML for color decoding (simplified and smaller)\n",
    "legend_html = f'''\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; width: 240px; height: 200px; \n",
    "                background-color: white; border: 2px solid grey; padding: 20px; \n",
    "                z-index: 9999; font-size: 10px; border-radius: 8px;\">\n",
    "        \n",
    "        <b>Passenger Density  Heat Map </b><br>\n",
    "        <b>Month:{month}</b> <br>\n",
    "        <b>Time Range: {start_time} - {end_time} </b>\n",
    "        <i style=\"background: blue; width: 20px; height: 20px; display: inline-block;\"></i> Low Density (0 - 20 passengers)<br>\n",
    "        <i style=\"background: green; width: 20px; height: 20px; display: inline-block;\"></i> Medium Density (21 - 500 passengers)<br>\n",
    "        <i style=\"background: orange; width: 20px; height: 20px; display: inline-block;\"></i> High Density (501 - 1000 passengers)<br>\n",
    "        <i style=\"background: red; width: 20px; height: 20px; display: inline-block;\"></i> Very High Density (1000+ passengers)<br>\n",
    "    </div>\n",
    "'''\n",
    "\n",
    "# Add the legend to the map\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save map to an HTML file\n",
    "m.save(\"passenger_boarding_density_fff.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
